# Data Quality e Insights EstratÃ©gicos com Databricks e PySpark

## ğŸ“Œ VisÃ£o Geral
Este projeto Ã© uma **Prova de Conceito (PoC)** desenvolvida como estudo prÃ¡tico no Databricks, utilizando **PySpark** para explorar, tratar e gerar insights a partir de dados de uma **loja virtual fictÃ­cia**.  
O foco foi **aumentar a qualidade dos dados** e estruturar informaÃ§Ãµes que auxiliam na **tomada de decisÃ£o estratÃ©gica** do negÃ³cio.

---

## ğŸ› ï¸ Tecnologias Utilizadas
- **Databricks Community Edition**
- **Apache Spark / PySpark**
- **Delta Lake**
- **DBFS (Databricks File System)**
- **Python 3**

---

## ğŸ“‚ Estrutura dos Dados
O projeto utilizou 8 arquivos CSV representando o ecossistema de uma loja virtual:

- `categorias.csv` â†’ categorias de produtos  
- `cidades.csv` â†’ cidades de clientes e vendedores  
- `clientes.csv` â†’ cadastro de clientes  
- `paises.csv` â†’ paÃ­ses relacionados a clientes e vendedores  
- `produtos.csv` â†’ informaÃ§Ãµes de produtos  
- `vendedores.csv` â†’ cadastro de vendedores  
- `vendas1.csv`, `vendas2.csv`, `vendas3.csv` â†’ dados de vendas em diferentes perÃ­odos  

> âš ï¸ Os arquivos CSV nÃ£o estÃ£o inclusos neste repositÃ³rio. A estrutura pode ser facilmente simulada em qualquer dataset de vendas para fins didÃ¡ticos.

---

## ğŸ§© Estrutura do Projeto
databricks-pyspark-case/
â”‚â”€â”€ notebooks/ # Notebooks com cada etapa do projeto
â”‚ â”œâ”€â”€ 01_setup_dbfs.ipynb
â”‚ â”œâ”€â”€ 02_ingestao_dados.ipynb
â”‚ â”œâ”€â”€ 03_limpeza_transformacao.ipynb
â”‚ â”œâ”€â”€ 04_modelagem_delta.ipynb
â”‚ â”œâ”€â”€ 05_consultas_sql.ipynb
â”‚ â”œâ”€â”€ 06_insights_negocio.ipynb
â”‚ â”œâ”€â”€ 07_rotinas_manutencao.ipynb
â”‚ â”œâ”€â”€ 08_dashboard_final.ipynb
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt # (opcional)
â”‚â”€â”€ LICENSE # (opcional)




---

## ğŸ¯ Funcionalidades
- IngestÃ£o de arquivos CSV no **DBFS**.  
- Tratamento e padronizaÃ§Ã£o dos dados com **PySpark**.  
- CriaÃ§Ã£o de tabelas otimizadas com **Delta Lake**.  
- Consultas exploratÃ³rias em **SQL e PySpark**.  
- GeraÃ§Ã£o de insights estratÃ©gicos para o negÃ³cio.  
- Rotinas de manutenÃ§Ã£o e versionamento de dados.  

---

## ğŸ“Š Exemplos de Insights
- IdentificaÃ§Ã£o dos **produtos mais vendidos**.  
- AnÃ¡lise do **desempenho por vendedor e regiÃ£o**.  
- Mapeamento de clientes com maior potencial de receita.  
- AvaliaÃ§Ã£o da **qualidade dos dados** (valores nulos, duplicados, inconsistÃªncias).  

---

## ğŸš€ Resultados
- Pipeline de ingestÃ£o e tratamento de dados configurado no Databricks.  
- Base de dados estruturada e otimizada em formato **Delta**.  
- InformaÃ§Ãµes consolidadas para **suporte Ã  decisÃ£o estratÃ©gica**.  
- Aprendizado prÃ¡tico em **Big Data com PySpark e Databricks**.  

---

## ğŸ“˜ Aprendizados
- EstruturaÃ§Ã£o de um ambiente **Data Lakehouse**.  
- IntegraÃ§Ã£o de dados heterogÃªneos em larga escala.  
- Boas prÃ¡ticas de manipulaÃ§Ã£o de dados com PySpark.  
- CriaÃ§Ã£o de rotinas de manutenÃ§Ã£o automatizadas.  

---

## ğŸ”— DocumentaÃ§Ã£o Completa
Para detalhes mais profundos (explicaÃ§Ã£o de cada notebook e prints dos resultados), acesse:  
ğŸ‘‰ [DocumentaÃ§Ã£o do Case no Notion](#) *(insira o link)*  

E confira tambÃ©m este case no meu portfÃ³lio online:  
ğŸ‘‰ [Landing Page Profissional](#) *(insira o link)*  

---

## ğŸ“œ LicenÃ§a
Este projeto foi desenvolvido para fins de estudo e portfÃ³lio. Licenciado sob [MIT](LICENSE).
